{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.dataset import read_lang_dataset, tokenize_dataset, get_vocab_mapping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['using', 'System', '.', 'Linq', ';', 'using', 'Microsoft', '.', 'CodeAnalysis', '.', 'CSharp', '.', 'Symbols', ';', 'namespace', 'Microsoft', '.', 'CodeAnalysis', '.', 'CSharp', '{', 'internal', 'static', 'class', 'CSharpCompilationExtensions', '{', 'int', 'VARIABLE', ';', 'internal', 'static', 'bool', 'IsFeatureEnabled', '(', 'this', 'CSharpCompilation', 'VARIABLE', ',', 'MessageID', 'VARIABLE', ')', '{', 'var', 'VARIABLE', '=', 'INT_LITERAL', ';', 'int', 'VARIABLE', '=', 'INT_LITERAL', '+', 'VARIABLE', ';', 'var', 'VARIABLE', '=', 'STRING_LITERAL', '+', 'STRING_LITERAL', ';', 'var', 'VARIABLE', '=', 'FLOAT_LITERAL', '+', 'VARIABLE', ';', 'return', 'null', ';', '}', '}', '}', '<EOF>']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from src.dataset import gateways, classpath\n",
    "gateways[0].jvm.com.codetokenizer.Tokenizer.tokenizeCsharp(\"\"\"\n",
    "// Licensed to the .NET Foundation under one or more agreements.\n",
    "// The .NET Foundation licenses this file to you under the MIT license.\n",
    "// See the LICENSE file in the project root for more information.\n",
    "\n",
    "using System.Linq;\n",
    "using Microsoft.CodeAnalysis.CSharp.Symbols;\n",
    "\n",
    "namespace Microsoft.CodeAnalysis.CSharp\n",
    "{\n",
    "    internal static class CSharpCompilationExtensions\n",
    "    {\n",
    "        int member;\n",
    "        internal static bool IsFeatureEnabled(this CSharpCompilation compilation, MessageID feature)\n",
    "        {\n",
    "            var a = 5;\n",
    "            int b = 0x5 + a;\n",
    "            var tst = \"abc\" + 'd';\n",
    "            var t = 56f + member;\n",
    "            return null;\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['using', 'namespace', 'std', ';', 'int', 'main', '(', ')', '{', 'int', 'VARIABLE', '=', 'INT_LITERAL', ',', 'VARIABLE', '=', 'INT_LITERAL', ',', 'VARIABLE', ';', 'cout', '<', '<', 'STRING_LITERAL', '<', '<', 'endl', ';', 'cout', '<', '<', 'STRING_LITERAL', '<', '<', 'VARIABLE', '<', '<', 'STRING_LITERAL', '<', '<', 'VARIABLE', '<', '<', 'endl', ';', 'VARIABLE', '=', 'VARIABLE', ';', 'VARIABLE', '=', 'VARIABLE', ';', 'VARIABLE', '=', 'VARIABLE', ';', 'cout', '<', '<', 'After', 'using', 'namespace', 'std', ';', 'int', 'VARIABLE', '(', ')', '{', 'int', 'VARIABLE', '=', 'INT_LITERAL', ',', 'VARIABLE', '=', 'INT_LITERAL', ',', 'VARIABLE', ';', 'cout', '<', '<', 'STRING_LITERAL', '<', '<', 'endl', ';', 'cout', '<', '<', 'STRING_LITERAL', '<', '<', 'VARIABLE', '<', '<', 'STRING_LITERAL', '<', '<', 'VARIABLE', '<', '<', 'endl', ';', 'VARIABLE', '=', 'VARIABLE', ';', 'VARIABLE', '=', 'VARIABLE', ';', 'VARIABLE', '=', 'VARIABLE', ';', 'cout', '<', '<', 'After', 'swapping', '.', 'cout', '<', '<', 'STRING_LITERAL', '<', '<', 'VARIABLE', '<', '<', 'STRING_LITERAL', '<', '<', 'VARIABLE', '<', '<', 'endl', ';', 'return', 'INT_LITERAL', ';', '}', '<EOF>']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gateways[0].jvm.com.codetokenizer.Tokenizer.tokenizeCpp(\"\"\"\n",
    "#include <iostream>\n",
    "using namespace std;\n",
    "\n",
    "int main()\n",
    "{\n",
    "    int a = 5, b = 10, temp;\n",
    "\n",
    "    cout << \"Before swapping.\" << endl;\n",
    "    cout << \"a = \" << a << \", b = \" << b << endl;\n",
    "\n",
    "    temp = a;\n",
    "    a = b;\n",
    "    b = temp;\n",
    "\n",
    "    cout << \"\\nAfter swapping.\" << endl;\n",
    "    cout << \"a = \" << a << \", b = \" << b << endl;\n",
    "\n",
    "    return 0;\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['package', 'samples', '\\n\\n', 'import', 'STRING_LITERAL', '\\n\\n', 'type', 'HpType', 'struct', '{', '}', '\\n\\n', 'func', '(', 'VARIABLE', 'HpType', ')', 'HP', '(', ')', '{', 'VARIABLE', ':=', 'STRING_LITERAL', '\\n\\n', 'fmt', '.', 'Printf', '(', 'STRING_LITERAL', ',', 'VARIABLE', ')', '\\n', 'VARIABLE', ':=', '[', ']', 'string', '{', 'STRING_LITERAL', ',', 'STRING_LITERAL', ',', 'STRING_LITERAL', ',', 'STRING_LITERAL', '}', '\\n', 'VARIABLE', '[', 'INT_LITERAL', ']', '=', 'STRING_LITERAL', '\\n\\n', 'VARIABLE', ':=', 'make', '(', '[', ']', 'string', ',', 'INT_LITERAL', ')', '\\n', 'VARIABLE', '=', 'append', '(', 'VARIABLE', ',', 'STRING_LITERAL', ',', 'STRING_LITERAL', ')', '\\n', 'fmt', '.', 'Println', '(', 'VARIABLE', ',', 'len', '(', 'VARIABLE', ')', ',', 'cap', '(', 'VARIABLE', ')', ')', '\\n', 'fmt', '.', 'Println', '(', 'VARIABLE', ',', 'len', '(', 'VARIABLE', ')', ',', 'cap', '(', 'VARIABLE', ')', ')', '\\n', '}', '\\n', '<EOF>']"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "gateways[0].jvm.com.codetokenizer.Tokenizer.tokenizeGo(\"\"\"\n",
    "package samples\n",
    "\n",
    "import \"fmt\"\n",
    "\n",
    "type HpType struct {\n",
    "}\n",
    "\n",
    "func (c HpType) HP() {\n",
    "\tpassword := `hardcoded`\n",
    "\n",
    "\tfmt.Printf(\"Hello, world\\nYou type the password=%v\\n\", password)\n",
    "\tletters := []string{\"a\", \"b\", \"c\", \"d\"}\n",
    "\tletters[3] = \"e\"\n",
    "\n",
    "\tp := make([]string, 10)\n",
    "\tp = append(letters, \"e\", \"f\")\n",
    "\tfmt.Println(letters, len(letters), cap(letters))\n",
    "\tfmt.Println(p, len(p), cap(p))\n",
    "}\n",
    "\"\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n from functools import partial \\n from typing import Dict , List , Optional , Tuple \\n from multiprocessing import Pool \\n import platform \\n BOOL_LITERAL , BOOL_LITERAL \\n if BOOL_LITERAL :        pass \\n \\n from tqdm import tqdm \\n import pandas as pd \\n import numpy as np \\n import swifter \\n from swifter import set_defaults \\n import sqlite3 \\n from py4j . java_gateway import JavaGateway , launch_gateway , GatewayParameters \\n set_defaults ( VARIABLE = BOOL_LITERAL , VARIABLE = BOOL_LITERAL ) \\n VARIABLE = STRING_LITERAL \\n VARIABLE = STRING_LITERAL \\n def _generic_regex_tokenization ( VARIABLE : pd . Series ) :        VARIABLE = STRING_LITERAL   VARIABLE = STRING_LITERAL   VARIABLE = STRING_LITERAL   VARIABLE = r [ VARIABLE - VARIABLE - VARIABLE - FLOAT_LITERAL _ \\n { } [ ] ( ) STRING_LITERAL   VARIABLE = ( STRING_LITERAL )   return ( code . str . lower ( ) . str . replace ( STRING_LITERAL , STRING_LITERAL , regex = BOOL_LITERAL ) . str . replace ( STRING_LITERAL , STRING_LITERAL , regex = BOOL_LITERAL ) . str . replace ( STRING_LITERAL , STRING_LITERAL , regex = BOOL_LITERAL ) . str . replace ( STRING_LITERAL , STRING_LITERAL , regex = BOOL_LITERAL ) . str . findall ( VARIABLE ) ) \\n VARIABLE = FLOAT_LITERAL \\n VARIABLE = FLOAT_LITERAL \\n VARIABLE = ( STRING_LITERAL ) \\n VARIABLE = STRING_LITERAL if platform . system ( ) == STRING_LITERAL else STRING_LITERAL \\n VARIABLE = VARIABLE . join ( [ VARIABLE ] ) \\n VARIABLE = launch_gateway ( VARIABLE = VARIABLE , die_on_exit = BOOL_LITERAL ) \\n VARIABLE = [ JavaGateway ( gateway_parameters = GatewayParameters ( port = VARIABLE ) ) for _ in range ( VARIABLE ) ] \\n def code_tokenize_par ( VARIABLE , VARIABLE ) :        VARIABLE , VARIABLE = VARIABLE   VARIABLE = getattr ( VARIABLE [ VARIABLE % VARIABLE ] . jvm . com . codetokenizer . Tokenizer , VARIABLE ) ( VARIABLE )   return list ( VARIABLE ) \\n \\n def _antlr_tokenization ( VARIABLE : pd . Series , VARIABLE : str ) :        with Pool ( VARIABLE ) as VARIABLE :            VARIABLE = pd . Series ( tqdm ( VARIABLE . imap ( partial ( code_tokenize_par , VARIABLE = VARIABLE ) , enumerate ( VARIABLE ) , ) , total = len ( VARIABLE ) , smoothing = FLOAT_LITERAL , ) , index = VARIABLE . index , dtype = object , )     return VARIABLE \\n \\n def _cpp_tokenization ( VARIABLE : pd . Series ) :        return _antlr_tokenization ( VARIABLE , STRING_LITERAL ) \\n \\n def _csharp_tokenization ( VARIABLE : pd . Series ) :        return _antlr_tokenization ( VARIABLE , STRING_LITERAL ) \\n \\n VARIABLE = { STRING_LITERAL : _cpp_tokenization , STRING_LITERAL : _csharp_tokenization } \\n def read_snippets_dataset ( VARIABLE : str , VARIABLE : Optional [ str ] = None ) -> pd . DataFrame :        VARIABLE = sqlite3 . connect ( VARIABLE )   VARIABLE = VARIABLE . cursor ( )   VARIABLE = VARIABLE . execute ( STRING_LITERAL )   if len ( list ( VARIABLE ) ) == FLOAT_LITERAL :            if VARIABLE is None :                VARIABLE = VARIABLE . execute ( STRING_LITERAL )     else :                VARIABLE = VARIABLE . execute ( STRING_LITERAL )       else :            if VARIABLE is None :                VARIABLE = VARIABLE . execute ( STRING_LITERAL )     else :                VARIABLE = VARIABLE . execute ( STRING_LITERAL )       return pd . DataFrame ( VARIABLE , columns = [ STRING_LITERAL , STRING_LITERAL ] ) \\n \\n def read_lang_dataset ( VARIABLE : str ) -> pd . DataFrame :        VARIABLE = sqlite3 . connect ( VARIABLE )   VARIABLE = VARIABLE . cursor ( )   VARIABLE = VARIABLE . execute ( STRING_LITERAL )   VARIABLE = pd . DataFrame ( VARIABLE , columns = [ STRING_LITERAL , STRING_LITERAL ] )   VARIABLE . VARIABLE = VARIABLE . VARIABLE . str . decode ( STRING_LITERAL , errors = STRING_LITERAL )   return VARIABLE \\n \\n def tokenize_dataset ( VARIABLE : pd . DataFrame ) :        VARIABLE = VARIABLE . copy ( )   for language in VARIABLE . language . unique ( ) :            VARIABLE = VARIABLE . code [ VARIABLE . language == language ]   if language in VARIABLE :                VARIABLE . code [ VARIABLE . VARIABLE == VARIABLE ] = VARIABLE [ VARIABLE ] ( VARIABLE )     else :                VARIABLE . code [ VARIABLE . VARIABLE == VARIABLE ] = _generic_regex_tokenization ( VARIABLE )       return VARIABLE \\n \\n def get_vocab_mapping ( VARIABLE : pd . DataFrame , ) -> Tuple [ Dict [ str , int ] , List [ str ] ] :        VARIABLE = set ( )   VARIABLE [ STRING_LITERAL ] . apply ( VARIABLE . VARIABLE )   VARIABLE = sorted ( VARIABLE )   VARIABLE = VARIABLE   VARIABLE = { w : i for i , w in enumerate ( VARIABLE ) }   return VARIABLE , VARIABLE \\n \\n <EOF>'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pycode = \" \".join(gateways[0].jvm.com.codetokenizer.Tokenizer.tokenizePython3(\"\"\"\n",
    "from functools import partial\n",
    "from typing import Dict, List, Optional, Tuple\n",
    "from multiprocessing import Pool\n",
    "import platform\n",
    "\n",
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import swifter\n",
    "from swifter import set_defaults\n",
    "import sqlite3\n",
    "from py4j.java_gateway import JavaGateway, launch_gateway, GatewayParameters\n",
    "\n",
    "set_defaults(allow_dask_on_strings=True, progress_bar=True)\n",
    "\n",
    "STRING_LITERAL_TOKEN = \"STRING_LITERAL\"\n",
    "INT_LITERAL_TOKEN = \"INT_LITERAL\"\n",
    "\n",
    "\n",
    "def _generic_regex_tokenization(code: pd.Series):\n",
    "    # TODO: maybe consider \\t seperately for python and other such languages\n",
    "    vars_or_keywords = r\"\\w+\"\n",
    "    dot_operator = r\"\\.\"\n",
    "    # parantheses and other similar constructs\n",
    "    parantheses_like = r\"[<>/\\\\{}[\\]()'\\\"]\"\n",
    "    # almost \\W, but with some whitespaces. Captures rest of characters.\n",
    "    non_words = r\"[^a-zA-Z0-9_ \\t\\n\\.<>/\\\\{}[\\]()'\\\"]+\"\n",
    "    generic_regex = (\n",
    "        rf\"({vars_or_keywords}|{dot_operator}|{parantheses_like}|{non_words})\"\n",
    "    )\n",
    "\n",
    "    return (\n",
    "        code.str.lower()\n",
    "        .str.replace(r\"'(\\\\.|[^'\\\\])*'\", f\" {STRING_LITERAL_TOKEN} \", regex=True)\n",
    "        .str.replace(r'\"(\\\\.|[^\"\\\\])*\"', f\" {STRING_LITERAL_TOKEN} \", regex=True)\n",
    "        .str.replace(r\"0x(\\d|\\w)+\", f\" {INT_LITERAL_TOKEN} \", regex=True)\n",
    "        .str.replace(r\"\\d+\", f\" {INT_LITERAL_TOKEN} \", regex=True)\n",
    "        .str.findall(generic_regex)\n",
    "    )\n",
    "\n",
    "\n",
    "pool_size = 8\n",
    "# \"create_parser.(sh|bat)\" script will create this\n",
    "jarpath = (\n",
    "    \"./src/w2vtokenizer/target/w2vtokenizer-0.0.1-SNAPSHOT-jar-with-dependencies.jar\"\n",
    ")\n",
    "classpath_seperator = \";\" if platform.system() == \"Windows\" else \":\"\n",
    "classpath = classpath_seperator.join([jarpath])\n",
    "\n",
    "gateway_port = launch_gateway(classpath=classpath, die_on_exit=True)\n",
    "gateways = [\n",
    "    JavaGateway(gateway_parameters=GatewayParameters(port=gateway_port))\n",
    "    for _ in range(pool_size)\n",
    "]\n",
    "\n",
    "\n",
    "def code_tokenize_par(t, function_name):\n",
    "    i, code = t\n",
    "    res = getattr(\n",
    "        gateways[i % pool_size].jvm.com.codetokenizer.Tokenizer, function_name\n",
    "    )(code)\n",
    "    return list(res)\n",
    "\n",
    "\n",
    "def _antlr_tokenization(code: pd.Series, function_name: str):\n",
    "    with Pool(pool_size) as p:\n",
    "        tokenized_code = pd.Series(\n",
    "            tqdm(\n",
    "                p.imap(\n",
    "                    partial(code_tokenize_par, function_name=function_name),\n",
    "                    enumerate(code),\n",
    "                ),\n",
    "                total=len(code),\n",
    "                smoothing=0.01,\n",
    "            ),\n",
    "            index=code.index,\n",
    "            dtype=object,\n",
    "        )\n",
    "    return tokenized_code\n",
    "\n",
    "\n",
    "def _cpp_tokenization(code: pd.Series):\n",
    "    return _antlr_tokenization(code, \"tokenizeCpp\")\n",
    "\n",
    "\n",
    "def _csharp_tokenization(code: pd.Series):\n",
    "    return _antlr_tokenization(code, \"tokenizeCsharp\")\n",
    "\n",
    "\n",
    "SPECIALIZED_TOKENIZATION = {\"C++\": _cpp_tokenization, \"C#\": _csharp_tokenization}\n",
    "\n",
    "\n",
    "def read_snippets_dataset(\n",
    "    db_file_path: str, programming_language: Optional[str] = None\n",
    ") -> pd.DataFrame:\n",
    "    conn = sqlite3.connect(db_file_path)\n",
    "    cur = conn.cursor()\n",
    "\n",
    "    # check if database contains table \"progress\"\n",
    "    foo = cur.execute(\n",
    "        \"SELECT name FROM sqlite_master WHERE type='table' AND name='progress'\"\n",
    "    )\n",
    "    # \"our\" database\n",
    "    if len(list(foo)) == 0:\n",
    "        if programming_language is None:\n",
    "            snippets = cur.execute(\"SELECT language, snippet FROM snippets\")\n",
    "        else:\n",
    "            snippets = cur.execute(\n",
    "                f\"SELECT language, snippet FROM snippets WHERE language='{programming_language}'\"\n",
    "            )\n",
    "    else:\n",
    "        if programming_language is None:\n",
    "            snippets = cur.execute(\"SELECT language, content FROM code\")\n",
    "        else:\n",
    "            snippets = cur.execute(\n",
    "                f\"SELECT language, content FROM code WHERE language='{programming_language}'\"\n",
    "            )\n",
    "\n",
    "    return pd.DataFrame(snippets, columns=[\"language\", \"code\"])\n",
    "\n",
    "\n",
    "def read_lang_dataset(db_file_path: str) -> pd.DataFrame:\n",
    "    conn = sqlite3.connect(db_file_path)\n",
    "    cur = conn.cursor()\n",
    "    data = cur.execute(\"SELECT language, content FROM code\")\n",
    "    data = pd.DataFrame(data, columns=[\"language\", \"code\"])\n",
    "    data.code = data.code.str.decode(\"utf-8\", errors=\"replace\")\n",
    "    return data\n",
    "\n",
    "\n",
    "def tokenize_dataset(dataset: pd.DataFrame):\n",
    "    dataset = dataset.copy()\n",
    "    for language in dataset.language.unique():\n",
    "        code_selection = dataset.code[dataset.language == language]\n",
    "        if language in SPECIALIZED_TOKENIZATION:\n",
    "            dataset.code[dataset.language == language] = SPECIALIZED_TOKENIZATION[\n",
    "                language\n",
    "            ](code_selection)\n",
    "        else:\n",
    "            dataset.code[dataset.language == language] = _generic_regex_tokenization(\n",
    "                code_selection\n",
    "            )\n",
    "    return dataset\n",
    "\n",
    "\n",
    "def get_vocab_mapping(\n",
    "    whole_tokenized_dataset: pd.DataFrame,\n",
    ") -> Tuple[Dict[str, int], List[str]]:\n",
    "    # TODO: initialize with whole vocab\n",
    "    words = set()\n",
    "    whole_tokenized_dataset[\"code\"].apply(words.update)\n",
    "    words = sorted(words)\n",
    "    int2word = words\n",
    "    word2int = {w: i for i, w in enumerate(words)}\n",
    "    return word2int, int2word\n",
    "\"\"\"))\n",
    "pycode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " from functools import partial \n",
      " from typing import Dict , List , Optional , Tuple \n",
      " from multiprocessing import Pool \n",
      " import platform \n",
      " from tqdm import tqdm \n",
      " import pandas as pd \n",
      " import numpy as np \n",
      " import swifter \n",
      " from swifter import set_defaults \n",
      " import sqlite3 \n",
      " from py4j . java_gateway import JavaGateway , launch_gateway , GatewayParameters \n",
      " set_defaults ( VARIABLE = True , VARIABLE = True ) \n",
      " VARIABLE = STRING_LITERAL \n",
      " VARIABLE = STRING_LITERAL \n",
      " def _generic_regex_tokenization ( VARIABLE : pd . Series ) :        VARIABLE = STRING_LITERAL   VARIABLE = STRING_LITERAL   VARIABLE = STRING_LITERAL   VARIABLE = r [ VARIABLE - VARIABLE - VARIABLE - 9 _ \n",
      " { } [ ] ( ) STRING_LITERAL   VARIABLE = ( STRING_LITERAL )   return ( code . str . lower ( ) . str . replace ( STRING_LITERAL , STRING_LITERAL , regex = True ) . str . replace ( STRING_LITERAL , STRING_LITERAL , regex = True ) . str . replace ( STRING_LITERAL , STRING_LITERAL , regex = True ) . str . replace ( STRING_LITERAL , STRING_LITERAL , regex = True ) . str . findall ( VARIABLE ) ) \n",
      " VARIABLE = 8 \n",
      " VARIABLE = ( STRING_LITERAL ) \n",
      " VARIABLE = STRING_LITERAL if platform . system ( ) == STRING_LITERAL else STRING_LITERAL \n",
      " VARIABLE = VARIABLE . join ( [ VARIABLE ] ) \n",
      " VARIABLE = launch_gateway ( VARIABLE = VARIABLE , die_on_exit = True ) \n",
      " VARIABLE = [ JavaGateway ( gateway_parameters = GatewayParameters ( port = VARIABLE ) ) for _ in range ( VARIABLE ) ] \n",
      " def code_tokenize_par ( VARIABLE , VARIABLE ) :        VARIABLE , VARIABLE = VARIABLE   VARIABLE = getattr ( VARIABLE [ VARIABLE % VARIABLE ] . jvm . com . codetokenizer . Tokenizer , VARIABLE ) ( VARIABLE )   return list ( VARIABLE ) \n",
      " \n",
      " def _antlr_tokenization ( VARIABLE : pd . Series , VARIABLE : str ) :        with Pool ( VARIABLE ) as VARIABLE :            VARIABLE = pd . Series ( tqdm ( VARIABLE . imap ( partial ( code_tokenize_par , VARIABLE = VARIABLE ) , enumerate ( VARIABLE ) , ) , total = len ( VARIABLE ) , smoothing = 0.01 , ) , index = VARIABLE . index , dtype = object , )     return VARIABLE \n",
      " \n",
      " def _cpp_tokenization ( VARIABLE : pd . Series ) :        return _antlr_tokenization ( VARIABLE , STRING_LITERAL ) \n",
      " \n",
      " def _csharp_tokenization ( VARIABLE : pd . Series ) :        return _antlr_tokenization ( VARIABLE , STRING_LITERAL ) \n",
      " \n",
      " VARIABLE = { STRING_LITERAL : _cpp_tokenization , STRING_LITERAL : _csharp_tokenization } \n",
      " def read_snippets_dataset ( VARIABLE : str , VARIABLE : Optional [ str ] = None ) -> pd . DataFrame :        VARIABLE = sqlite3 . connect ( VARIABLE )   VARIABLE = VARIABLE . cursor ( )   VARIABLE = VARIABLE . execute ( STRING_LITERAL )   if len ( list ( VARIABLE ) ) == 0 :            if VARIABLE is None :                VARIABLE = VARIABLE . execute ( STRING_LITERAL )     else :                VARIABLE = VARIABLE . execute ( STRING_LITERAL )       else :            if VARIABLE is None :                VARIABLE = VARIABLE . execute ( STRING_LITERAL )     else :                VARIABLE = VARIABLE . execute ( STRING_LITERAL )       return pd . DataFrame ( VARIABLE , columns = [ STRING_LITERAL , STRING_LITERAL ] ) \n",
      " \n",
      " def read_lang_dataset ( VARIABLE : str ) -> pd . DataFrame :        VARIABLE = sqlite3 . connect ( VARIABLE )   VARIABLE = VARIABLE . cursor ( )   VARIABLE = VARIABLE . execute ( STRING_LITERAL )   VARIABLE = pd . DataFrame ( VARIABLE , columns = [ STRING_LITERAL , STRING_LITERAL ] )   VARIABLE . VARIABLE = VARIABLE . VARIABLE . str . decode ( STRING_LITERAL , errors = STRING_LITERAL )   return VARIABLE \n",
      " \n",
      " def tokenize_dataset ( VARIABLE : pd . DataFrame ) :        VARIABLE = VARIABLE . copy ( )   for language in VARIABLE . language . unique ( ) :            VARIABLE = VARIABLE . code [ VARIABLE . language == language ]   if language in VARIABLE :                VARIABLE . code [ VARIABLE . VARIABLE == VARIABLE ] = VARIABLE [ VARIABLE ] ( VARIABLE )     else :                VARIABLE . code [ VARIABLE . VARIABLE == VARIABLE ] = _generic_regex_tokenization ( VARIABLE )       return VARIABLE \n",
      " \n",
      " def get_vocab_mapping ( VARIABLE : pd . DataFrame , ) -> Tuple [ Dict [ str , int ] , List [ str ] ] :        VARIABLE = set ( )   VARIABLE [ STRING_LITERAL ] . apply ( VARIABLE . VARIABLE )   VARIABLE = sorted ( VARIABLE )   VARIABLE = VARIABLE   VARIABLE = { w : i for i , w in enumerate ( VARIABLE ) }   return VARIABLE , VARIABLE \n",
      " \n",
      " <EOF>\n"
     ]
    }
   ],
   "source": [
    "print(pycode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C#</td>\n",
       "      <td>using System;\\nusing System.Collections.Generi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C#</td>\n",
       "      <td>using System;\\nusing System.Collections.Generi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C#</td>\n",
       "      <td>using System.Collections.Generic;\\nusing Syste...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C#</td>\n",
       "      <td>using System;\\nusing System.Windows;\\nusing Sy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C#</td>\n",
       "      <td>using System;\\nusing System.Collections.Generi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1108</th>\n",
       "      <td>C#</td>\n",
       "      <td>using System;\\nusing System.Collections.Generi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1109</th>\n",
       "      <td>C#</td>\n",
       "      <td>// &lt;auto-generated /&gt;\\nusing System;\\nusing Mi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1110</th>\n",
       "      <td>C#</td>\n",
       "      <td>#pragma checksum \"C:\\Users\\gault\\Desktop\\Effic...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1111</th>\n",
       "      <td>C#</td>\n",
       "      <td>using System;\\nusing System.Collections.Generi...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1112</th>\n",
       "      <td>C#</td>\n",
       "      <td>#pragma checksum \"/Users/stephan/developer/dot...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1113 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     language                                               code\n",
       "0          C#  using System;\\nusing System.Collections.Generi...\n",
       "1          C#  using System;\\nusing System.Collections.Generi...\n",
       "2          C#  using System.Collections.Generic;\\nusing Syste...\n",
       "3          C#  using System;\\nusing System.Windows;\\nusing Sy...\n",
       "4          C#  using System;\\nusing System.Collections.Generi...\n",
       "...       ...                                                ...\n",
       "1108       C#  using System;\\nusing System.Collections.Generi...\n",
       "1109       C#  // <auto-generated />\\nusing System;\\nusing Mi...\n",
       "1110       C#  #pragma checksum \"C:\\Users\\gault\\Desktop\\Effic...\n",
       "1111       C#  using System;\\nusing System.Collections.Generi...\n",
       "1112       C#  #pragma checksum \"/Users/stephan/developer/dot...\n",
       "\n",
       "[1113 rows x 2 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csharp_df = read_lang_dataset(\"data/csharp_codes.db\")\n",
    "csharp_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>C#</td>\n",
       "      <td>/*********************************************...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>C#</td>\n",
       "      <td>//--------------------------------------------...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language                                               code\n",
       "1024       C#  /*********************************************...\n",
       "51         C#  //--------------------------------------------..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = csharp_df.sample(2)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2/2 [00:01<00:00,  1.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1024</th>\n",
       "      <td>C#</td>\n",
       "      <td>[using, System, ;, using, System, ., Component...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51</th>\n",
       "      <td>C#</td>\n",
       "      <td>[using, System, ., Collections, ., Generic, ;,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     language                                               code\n",
       "1024       C#  [using, System, ;, using, System, ., Component...\n",
       "51         C#  [using, System, ., Collections, ., Generic, ;,..."
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenized_sample = tokenize_dataset(sample)\n",
    "tokenized_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'//---------------------------------------------------------------------------\\n//\\n// Copyright (C) Microsoft Corporation.  All rights reserved.\\n// \\n// File: ContentTextElementAutomationPeer.cs\\n//\\n// Description: Base class for AutomationPeers associated with TextPattern.\\n//\\n//---------------------------------------------------------------------------\\n\\nusing System.Collections.Generic;           // List<T>\\nusing System.Windows.Automation.Provider;   // IRawElementProviderSimple\\nusing System.Windows.Documents;             // ITextPointer\\n\\nnamespace System.Windows.Automation.Peers\\n{\\n    /// <summary>\\n    /// Base class for AutomationPeers associated with TextPattern.\\n    /// </summary>\\n    public abstract class TextAutomationPeer : FrameworkElementAutomationPeer\\n    {\\n        /// <summary>\\n        /// Constructor.\\n        /// </summary>\\n        protected TextAutomationPeer(FrameworkElement owner)\\n            : base(owner)\\n        {}\\n\\n        /// <summary>\\n        /// GetNameCore will return a value matching (in priority order)\\n        ///\\n        /// 1. Automation.Name\\n        /// 2. GetLabeledBy.Name \\n        /// 3. String.Empty \\n        /// \\n        /// This differs from the base implementation in that we must\\n        /// never return GetPlainText() .\\n        /// </summary>\\n        override protected string GetNameCore()\\n        {\\n            string result = AutomationProperties.GetName(this.Owner);\\n\\n            if (string.IsNullOrEmpty(result))\\n            {\\n                AutomationPeer labelAutomationPeer = GetLabeledByCore();\\n                if (labelAutomationPeer != null)\\n                {\\n                    result = labelAutomationPeer.GetName();\\n                }\\n            }\\n\\n            return result ?? string.Empty;\\n        }\\n\\n        /// <summary>\\n        /// Maps AutomationPeer to provider object.\\n        /// </summary>\\n        internal new IRawElementProviderSimple ProviderFromPeer(AutomationPeer peer)\\n        {\\n            return base.ProviderFromPeer(peer);\\n        }\\n\\n        /// <summary>\\n        /// Maps automation provider to DependencyObject.\\n        /// </summary>\\n        internal DependencyObject ElementFromProvider(IRawElementProviderSimple provider)\\n        {\\n            DependencyObject element = null;\\n            AutomationPeer peer = PeerFromProvider(provider);\\n            if (peer is UIElementAutomationPeer)\\n            {\\n                element = ((UIElementAutomationPeer)peer).Owner;\\n            }\\n            else if (peer is ContentElementAutomationPeer)\\n            {\\n                element = ((ContentElementAutomationPeer)peer).Owner;\\n            }\\n            return element;\\n        }\\n\\n        /// <summary>\\n        /// Gets collection of AutomationPeers for given text range.\\n        /// </summary>\\n        internal abstract List<AutomationPeer> GetAutomationPeersFromRange(ITextPointer start, ITextPointer end);\\n    }\\n}\\n\\n\\n'"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample.code.iloc[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'using System . Collections . Generic ; using System . Windows . Automation . Provider ; using System . Windows . Documents ; namespace System . Windows . Automation . Peers { public abstract class TextAutomationPeer : FrameworkElementAutomationPeer { protected TextAutomationPeer ( FrameworkElement VARIABLE ) : base ( VARIABLE ) { } override protected string GetNameCore ( ) { string VARIABLE = AutomationProperties . GetName ( this . Owner ) ; if ( string . IsNullOrEmpty ( VARIABLE ) ) { AutomationPeer VARIABLE = GetLabeledByCore ( ) ; if ( VARIABLE != null ) { VARIABLE = VARIABLE . GetName ( ) ; } } return VARIABLE ?? string . Empty ; } internal new IRawElementProviderSimple ProviderFromPeer ( AutomationPeer VARIABLE ) { return base . ProviderFromPeer ( VARIABLE ) ; } internal DependencyObject ElementFromProvider ( IRawElementProviderSimple VARIABLE ) { DependencyObject VARIABLE = null ; AutomationPeer VARIABLE = PeerFromProvider ( VARIABLE ) ; if ( VARIABLE is UIElementAutomationPeer ) { VARIABLE = ( ( UIElementAutomationPeer ) VARIABLE ) . Owner ; } else if ( VARIABLE is ContentElementAutomationPeer ) { VARIABLE = ( ( ContentElementAutomationPeer ) VARIABLE ) . Owner ; } return VARIABLE ; } internal abstract List < AutomationPeer > GetAutomationPeersFromRange ( ITextPointer VARIABLE , ITextPointer VARIABLE ) ; } } <EOF>'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "' '.join(tokenized_sample.code.iloc[1][:550])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[11], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mseed(\u001b[39m42\u001b[39m)\n\u001b[1;32m----> 2\u001b[0m sample \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39msample(\u001b[39m3\u001b[39m)\n\u001b[0;32m      3\u001b[0m \u001b[39mfor\u001b[39;00m i, language, code \u001b[39min\u001b[39;00m sample\u001b[39m.\u001b[39mitertuples():\n\u001b[0;32m      4\u001b[0m     \u001b[39mprint\u001b[39m(\u001b[39mf\u001b[39m\u001b[39m\"\u001b[39m\u001b[39m###### Index \u001b[39m\u001b[39m{\u001b[39;00mi\u001b[39m:\u001b[39;00m\u001b[39m7\u001b[39m\u001b[39m}\u001b[39;00m\u001b[39m ######\u001b[39m\u001b[39m\"\u001b[39m)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'data' is not defined"
     ]
    }
   ],
   "source": [
    "np.random.seed(42)\n",
    "sample = data.sample(3)\n",
    "for i, language, code in sample.itertuples():\n",
    "    print(f\"###### Index {i:7} ######\")\n",
    "    print(code)\n",
    "    print(f\"###########################\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 3/3 [00:01<00:00,  2.06it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>77165</th>\n",
       "      <td>C++</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>307910</th>\n",
       "      <td>C++</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79469</th>\n",
       "      <td>C++</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       language code\n",
       "77165       C++   []\n",
       "307910      C++   []\n",
       "79469       C++   []"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sample = tokenize_dataset(sample)\n",
    "sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "for language, code in sample.itertuples(False):\n",
    "    print(code)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 327126/327126 [04:00<00:00, 1357.60it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>C++</td>\n",
       "      <td>[http, :, Unless, required, http, Unless, requ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>C++</td>\n",
       "      <td>[&lt;EOF&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>C++</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>C++</td>\n",
       "      <td>[AddError, (, INT_LITERAL, ,, INT_LITERAL, ,, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>C++</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327121</th>\n",
       "      <td>C++</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327122</th>\n",
       "      <td>C++</td>\n",
       "      <td>[&lt;EOF&gt;]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327123</th>\n",
       "      <td>C++</td>\n",
       "      <td>[]</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327124</th>\n",
       "      <td>C++</td>\n",
       "      <td>[assert, (, not_found, ==, answer1, ), ;, answ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>327125</th>\n",
       "      <td>C++</td>\n",
       "      <td>[SetObjectField, (, newUserData, ,, nameField,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>327126 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       language                                               code\n",
       "0           C++  [http, :, Unless, required, http, Unless, requ...\n",
       "1           C++                                            [<EOF>]\n",
       "2           C++                                                 []\n",
       "3           C++  [AddError, (, INT_LITERAL, ,, INT_LITERAL, ,, ...\n",
       "4           C++                                                 []\n",
       "...         ...                                                ...\n",
       "327121      C++                                                 []\n",
       "327122      C++                                            [<EOF>]\n",
       "327123      C++                                                 []\n",
       "327124      C++  [assert, (, not_found, ==, answer1, ), ;, answ...\n",
       "327125      C++  [SetObjectField, (, newUserData, ,, nameField,...\n",
       "\n",
       "[327126 rows x 2 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenize_dataset(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>language</th>\n",
       "      <th>code</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Python</td>\n",
       "      <td>version = '7'\\nhtml_title = \"Guzzle Documentat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Python</td>\n",
       "      <td># Path to a touch icon\\n    # \"touch_icon\"...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Python</td>\n",
       "      <td>\"base_url\": \"http://guzzlephp.org\"\\n\\n    ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Python</td>\n",
       "      <td>from tensorflow.python.estimator.model_fn impo...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Python</td>\n",
       "      <td>self.assertFalse(gfile.Exists('ram://exist...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546444</th>\n",
       "      <td>C++</td>\n",
       "      <td>* * Worst Time Complexity O(log n)\\n * * Best...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546445</th>\n",
       "      <td>C++</td>\n",
       "      <td>/**\\n * \\file\\n * \\brief [Interpolation\\n * se...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546446</th>\n",
       "      <td>C++</td>\n",
       "      <td>std::cin &gt;&gt; n;\\n\\n    int *array = new int...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546447</th>\n",
       "      <td>C++</td>\n",
       "      <td>assert(not_found == answer1);\\n    // Test...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1546448</th>\n",
       "      <td>C++</td>\n",
       "      <td>env-&gt;SetObjectField(newUserData, nameField...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1546449 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        language                                               code\n",
       "0         Python  version = '7'\\nhtml_title = \"Guzzle Documentat...\n",
       "1         Python      # Path to a touch icon\\n    # \"touch_icon\"...\n",
       "2         Python      \"base_url\": \"http://guzzlephp.org\"\\n\\n    ...\n",
       "3         Python  from tensorflow.python.estimator.model_fn impo...\n",
       "4         Python      self.assertFalse(gfile.Exists('ram://exist...\n",
       "...          ...                                                ...\n",
       "1546444      C++   * * Worst Time Complexity O(log n)\\n * * Best...\n",
       "1546445      C++  /**\\n * \\file\\n * \\brief [Interpolation\\n * se...\n",
       "1546446      C++      std::cin >> n;\\n\\n    int *array = new int...\n",
       "1546447      C++      assert(not_found == answer1);\\n    // Test...\n",
       "1546448      C++      env->SetObjectField(newUserData, nameField...\n",
       "\n",
       "[1546449 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "datasets = [read_dataset(dataset_path, language) for language in [\"Python\", \"Go\", \"C\", \"C++\"]]\n",
    "datasets = pd.concat(datasets, ignore_index=True)\n",
    "datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 54%|█████▍    | 176115/327126 [02:03<01:46, 1422.12it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "File \u001b[1;32mC:\\Python310\\lib\\multiprocessing\\pool.py:853\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    852\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m--> 853\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_items\u001b[39m.\u001b[39;49mpopleft()\n\u001b[0;32m    854\u001b[0m \u001b[39mexcept\u001b[39;00m \u001b[39mIndexError\u001b[39;00m:\n",
      "\u001b[1;31mIndexError\u001b[0m: pop from an empty deque",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[9], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m tokenized \u001b[39m=\u001b[39m tokenize_dataset(datasets)\n\u001b[0;32m      2\u001b[0m tokenized\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\Documents\\vos\\w22air\\programming-languages-w2v\\src\\dataset.py:102\u001b[0m, in \u001b[0;36mtokenize_dataset\u001b[1;34m(dataset)\u001b[0m\n\u001b[0;32m     99\u001b[0m code_selection \u001b[39m=\u001b[39m dataset\u001b[39m.\u001b[39mcode[dataset\u001b[39m.\u001b[39mlanguage \u001b[39m==\u001b[39m language]\n\u001b[0;32m    100\u001b[0m \u001b[39mif\u001b[39;00m language \u001b[39min\u001b[39;00m SPECIALIZED_TOKENIZATION:\n\u001b[0;32m    101\u001b[0m     dataset\u001b[39m.\u001b[39mcode[dataset\u001b[39m.\u001b[39mlanguage \u001b[39m==\u001b[39m language] \u001b[39m=\u001b[39m SPECIALIZED_TOKENIZATION[\n\u001b[1;32m--> 102\u001b[0m         language\n\u001b[0;32m    103\u001b[0m     ](code_selection)\n\u001b[0;32m    104\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m    105\u001b[0m     dataset\u001b[39m.\u001b[39mcode[dataset\u001b[39m.\u001b[39mlanguage \u001b[39m==\u001b[39m language] \u001b[39m=\u001b[39m _generic_regex_tokenization(\n\u001b[0;32m    106\u001b[0m         code_selection\n\u001b[0;32m    107\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\Documents\\vos\\w22air\\programming-languages-w2v\\src\\dataset.py:68\u001b[0m, in \u001b[0;36m_cpp_tokenization\u001b[1;34m(code)\u001b[0m\n\u001b[0;32m     65\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_cpp_tokenization\u001b[39m(code: pd\u001b[39m.\u001b[39mSeries):\n\u001b[0;32m     66\u001b[0m     \u001b[39mwith\u001b[39;00m Pool(pool_size) \u001b[39mas\u001b[39;00m p:\n\u001b[0;32m     67\u001b[0m         tokenized_code \u001b[39m=\u001b[39m pd\u001b[39m.\u001b[39mSeries(\n\u001b[1;32m---> 68\u001b[0m             tqdm(\n\u001b[0;32m     69\u001b[0m                 p\u001b[39m.\u001b[39mimap(code_tokenize_par, \u001b[39menumerate\u001b[39m(code)),\n\u001b[0;32m     70\u001b[0m                 total\u001b[39m=\u001b[39m\u001b[39mlen\u001b[39m(code),\n\u001b[0;32m     71\u001b[0m                 smoothing\u001b[39m=\u001b[39m\u001b[39m0.01\u001b[39m,\n\u001b[0;32m     72\u001b[0m             ),\n\u001b[0;32m     73\u001b[0m             index\u001b[39m=\u001b[39mcode\u001b[39m.\u001b[39mindex,\n\u001b[0;32m     74\u001b[0m             dtype\u001b[39m=\u001b[39m\u001b[39mobject\u001b[39m,\n\u001b[0;32m     75\u001b[0m         )\n\u001b[0;32m     76\u001b[0m     \u001b[39mreturn\u001b[39;00m tokenized_code\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\Documents\\vos\\w22air\\programming-languages-w2v\\env\\lib\\site-packages\\swifter\\swifter.py:41\u001b[0m, in \u001b[0;36mregister_default_config_dataframe_accessor.<locals>.new_init\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m     40\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mnew_init\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds):\n\u001b[1;32m---> 41\u001b[0m     current_init(\u001b[39mself\u001b[39m, \u001b[39m*\u001b[39margs, \u001b[39m*\u001b[39m\u001b[39m*\u001b[39mkwds)\n\u001b[0;32m     42\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mswifter \u001b[39m=\u001b[39m (\n\u001b[0;32m     43\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mswifter\u001b[39m.\u001b[39mset_npartitions(npartitions\u001b[39m=\u001b[39mkwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mnpartitions\u001b[39m\u001b[39m\"\u001b[39m, DEFAULT_KWARGS[\u001b[39m\"\u001b[39m\u001b[39mnpartitions\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[0;32m     44\u001b[0m         \u001b[39m.\u001b[39mset_dask_threshold(dask_threshold\u001b[39m=\u001b[39mkwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mdask_threshold\u001b[39m\u001b[39m\"\u001b[39m, DEFAULT_KWARGS[\u001b[39m\"\u001b[39m\u001b[39mdask_threshold\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m     51\u001b[0m         \u001b[39m.\u001b[39mforce_parallel(enable\u001b[39m=\u001b[39mkwargs\u001b[39m.\u001b[39mget(\u001b[39m\"\u001b[39m\u001b[39mforce_parallel\u001b[39m\u001b[39m\"\u001b[39m, DEFAULT_KWARGS[\u001b[39m\"\u001b[39m\u001b[39mforce_parallel\u001b[39m\u001b[39m\"\u001b[39m]))\n\u001b[0;32m     52\u001b[0m     )\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\Documents\\vos\\w22air\\programming-languages-w2v\\env\\lib\\site-packages\\pandas\\core\\series.py:470\u001b[0m, in \u001b[0;36mSeries.__init__\u001b[1;34m(self, data, index, dtype, name, copy, fastpath)\u001b[0m\n\u001b[0;32m    468\u001b[0m         data \u001b[39m=\u001b[39m data\u001b[39m.\u001b[39mcopy()\n\u001b[0;32m    469\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 470\u001b[0m     data \u001b[39m=\u001b[39m sanitize_array(data, index, dtype, copy)\n\u001b[0;32m    472\u001b[0m     manager \u001b[39m=\u001b[39m get_option(\u001b[39m\"\u001b[39m\u001b[39mmode.data_manager\u001b[39m\u001b[39m\"\u001b[39m)\n\u001b[0;32m    473\u001b[0m     \u001b[39mif\u001b[39;00m manager \u001b[39m==\u001b[39m \u001b[39m\"\u001b[39m\u001b[39mblock\u001b[39m\u001b[39m\"\u001b[39m:\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\Documents\\vos\\w22air\\programming-languages-w2v\\env\\lib\\site-packages\\pandas\\core\\construction.py:618\u001b[0m, in \u001b[0;36msanitize_array\u001b[1;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001b[0m\n\u001b[0;32m    616\u001b[0m     data \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray(data, copy\u001b[39m=\u001b[39mcopy)\n\u001b[0;32m    617\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m--> 618\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mlist\u001b[39;49m(data)\n\u001b[0;32m    620\u001b[0m \u001b[39mif\u001b[39;00m dtype \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mor\u001b[39;00m \u001b[39mlen\u001b[39m(data) \u001b[39m==\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m    621\u001b[0m     \u001b[39mtry\u001b[39;00m:\n",
      "File \u001b[1;32mc:\\Users\\Kevin\\Documents\\vos\\w22air\\programming-languages-w2v\\env\\lib\\site-packages\\tqdm\\std.py:1195\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1192\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1194\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1195\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1196\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1197\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1198\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mC:\\Python310\\lib\\multiprocessing\\pool.py:858\u001b[0m, in \u001b[0;36mIMapIterator.next\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    856\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pool \u001b[39m=\u001b[39m \u001b[39mNone\u001b[39;00m\n\u001b[0;32m    857\u001b[0m     \u001b[39mraise\u001b[39;00m \u001b[39mStopIteration\u001b[39;00m \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39m\n\u001b[1;32m--> 858\u001b[0m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_cond\u001b[39m.\u001b[39;49mwait(timeout)\n\u001b[0;32m    859\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[0;32m    860\u001b[0m     item \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_items\u001b[39m.\u001b[39mpopleft()\n",
      "File \u001b[1;32mC:\\Python310\\lib\\threading.py:320\u001b[0m, in \u001b[0;36mCondition.wait\u001b[1;34m(self, timeout)\u001b[0m\n\u001b[0;32m    318\u001b[0m \u001b[39mtry\u001b[39;00m:    \u001b[39m# restore state no matter what (e.g., KeyboardInterrupt)\u001b[39;00m\n\u001b[0;32m    319\u001b[0m     \u001b[39mif\u001b[39;00m timeout \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[1;32m--> 320\u001b[0m         waiter\u001b[39m.\u001b[39;49macquire()\n\u001b[0;32m    321\u001b[0m         gotit \u001b[39m=\u001b[39m \u001b[39mTrue\u001b[39;00m\n\u001b[0;32m    322\u001b[0m     \u001b[39melse\u001b[39;00m:\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "tokenized = tokenize_dataset(datasets)\n",
    "tokenized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mFailed to start the Kernel. \n",
      "\u001b[1;31mUnable to start Kernel 'env (Python 3.10.5)' due to connection timeout. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "words2int, int2word = get_vocab_mapping(tokenized)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ba882bed1965a54d4fef669f18faecb8d8e732d30288b3c8a5015454ba0d6c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
