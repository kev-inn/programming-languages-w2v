{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "from typing import List, Tuple\n",
    "\n",
    "import os\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import gensim\n",
    "from gensim.models import Word2Vec\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from src.dataset import read_lang_dataset, tokenize_dataset, get_vocab_mapping, gateways\n",
    "\n",
    "sns.set_theme()\n",
    "sns.set(rc={'figure.figsize': (12, 8)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "     language                                               code\n0      Python  \"\"\"The tests for the automation component.\"\"\"\\...\n1      Python  #!python2\\n# -*- coding: utf-8 -*-\\nimport os\\...\n2      Python  #!/usr/bin/python\\n#\\n# Copyright (c) 2017 Yuw...\n3      Python  \"\"\"The tests for the Template automation.\"\"\"\\n...\n4      Python  \"\"\"The tests for numeric state automation.\"\"\"\\...\n...       ...                                                ...\n9468       C#  using Microsoft.SharePoint.Client;\\nusing Micr...\n9469       C#  using System;\\nusing System.Collections;\\nusin...\n9470       C#  using UnityEngine;\\nusing System.Collections.G...\n9471       C#  // Copyright (c) Microsoft Corporation. All ri...\n9472       C#  using NUnit.Framework;\\nusing UnityEngine.Loca...\n\n[9473 rows x 2 columns]",
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>language</th>\n      <th>code</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Python</td>\n      <td>\"\"\"The tests for the automation component.\"\"\"\\...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Python</td>\n      <td>#!python2\\n# -*- coding: utf-8 -*-\\nimport os\\...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Python</td>\n      <td>#!/usr/bin/python\\n#\\n# Copyright (c) 2017 Yuw...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Python</td>\n      <td>\"\"\"The tests for the Template automation.\"\"\"\\n...</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Python</td>\n      <td>\"\"\"The tests for numeric state automation.\"\"\"\\...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>9468</th>\n      <td>C#</td>\n      <td>using Microsoft.SharePoint.Client;\\nusing Micr...</td>\n    </tr>\n    <tr>\n      <th>9469</th>\n      <td>C#</td>\n      <td>using System;\\nusing System.Collections;\\nusin...</td>\n    </tr>\n    <tr>\n      <th>9470</th>\n      <td>C#</td>\n      <td>using UnityEngine;\\nusing System.Collections.G...</td>\n    </tr>\n    <tr>\n      <th>9471</th>\n      <td>C#</td>\n      <td>// Copyright (c) Microsoft Corporation. All ri...</td>\n    </tr>\n    <tr>\n      <th>9472</th>\n      <td>C#</td>\n      <td>using NUnit.Framework;\\nusing UnityEngine.Loca...</td>\n    </tr>\n  </tbody>\n</table>\n<p>9473 rows × 2 columns</p>\n</div>"
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = read_lang_dataset(\"data/dataset_github_codes.db\")\n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": "C++       2688\nC#        2494\nGo        2203\nPython    2088\nName: language, dtype: int64"
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset.language.value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 2088/2088 [01:12<00:00, 28.67it/s]\n",
      " 57%|█████▋    | 1411/2494 [00:15<00:11, 93.08it/s]\n"
     ]
    },
    {
     "ename": "MaybeEncodingError",
     "evalue": "Error sending result: '<multiprocessing.pool.ExceptionWithTraceback object at 0x7fc090124400>'. Reason: 'TypeError(\"cannot pickle '_thread.RLock' object\")'",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mMaybeEncodingError\u001B[0m                        Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[4], line 1\u001B[0m\n\u001B[0;32m----> 1\u001B[0m tokenized_sample \u001B[38;5;241m=\u001B[39m \u001B[43mtokenize_dataset\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdataset\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m      2\u001B[0m tokenized_sample\n",
      "File \u001B[0;32m~/Documents/git/programming-languages-w2v/src/dataset.py:125\u001B[0m, in \u001B[0;36mtokenize_dataset\u001B[0;34m(dataset)\u001B[0m\n\u001B[1;32m    123\u001B[0m code_selection \u001B[38;5;241m=\u001B[39m dataset\u001B[38;5;241m.\u001B[39mcode[dataset\u001B[38;5;241m.\u001B[39mlanguage \u001B[38;5;241m==\u001B[39m language]\n\u001B[1;32m    124\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m language \u001B[38;5;129;01min\u001B[39;00m SPECIALIZED_TOKENIZATION:\n\u001B[0;32m--> 125\u001B[0m     dataset\u001B[38;5;241m.\u001B[39mcode[dataset\u001B[38;5;241m.\u001B[39mlanguage \u001B[38;5;241m==\u001B[39m language] \u001B[38;5;241m=\u001B[39m \u001B[43mSPECIALIZED_TOKENIZATION\u001B[49m\u001B[43m[\u001B[49m\n\u001B[1;32m    126\u001B[0m \u001B[43m        \u001B[49m\u001B[43mlanguage\u001B[49m\n\u001B[1;32m    127\u001B[0m \u001B[43m    \u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcode_selection\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    128\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    129\u001B[0m     dataset\u001B[38;5;241m.\u001B[39mcode[dataset\u001B[38;5;241m.\u001B[39mlanguage \u001B[38;5;241m==\u001B[39m language] \u001B[38;5;241m=\u001B[39m _generic_regex_tokenization(\n\u001B[1;32m    130\u001B[0m         code_selection\n\u001B[1;32m    131\u001B[0m     )\n",
      "File \u001B[0;32m~/Documents/git/programming-languages-w2v/src/dataset.py:68\u001B[0m, in \u001B[0;36m_antlr_tokenization\u001B[0;34m(code, function_name)\u001B[0m\n\u001B[1;32m     66\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_antlr_tokenization\u001B[39m(code: pd\u001B[38;5;241m.\u001B[39mSeries, function_name: \u001B[38;5;28mstr\u001B[39m):\n\u001B[1;32m     67\u001B[0m     \u001B[38;5;28;01mwith\u001B[39;00m Pool(pool_size) \u001B[38;5;28;01mas\u001B[39;00m p:\n\u001B[0;32m---> 68\u001B[0m         tokenized_code \u001B[38;5;241m=\u001B[39m \u001B[43mpd\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mSeries\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     69\u001B[0m \u001B[43m            \u001B[49m\u001B[43mtqdm\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     70\u001B[0m \u001B[43m                \u001B[49m\u001B[43mp\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mimap\u001B[49m\u001B[43m(\u001B[49m\n\u001B[1;32m     71\u001B[0m \u001B[43m                    \u001B[49m\u001B[43mpartial\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcode_tokenize_par\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mfunction_name\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mfunction_name\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     72\u001B[0m \u001B[43m                    \u001B[49m\u001B[38;5;28;43menumerate\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcode\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     73\u001B[0m \u001B[43m                \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     74\u001B[0m \u001B[43m                \u001B[49m\u001B[43mtotal\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mlen\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mcode\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     75\u001B[0m \u001B[43m                \u001B[49m\u001B[43msmoothing\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m0.0001\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     76\u001B[0m \u001B[43m            \u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     77\u001B[0m \u001B[43m            \u001B[49m\u001B[43mindex\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcode\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\n\u001B[1;32m     78\u001B[0m \u001B[43m            \u001B[49m\u001B[43mdtype\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;28;43mobject\u001B[39;49m\u001B[43m,\u001B[49m\n\u001B[1;32m     79\u001B[0m \u001B[43m        \u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     80\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m tokenized_code\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/programming-languages-w2v-9GOOA69h-py3.10/lib/python3.10/site-packages/pandas/core/series.py:470\u001B[0m, in \u001B[0;36mSeries.__init__\u001B[0;34m(self, data, index, dtype, name, copy, fastpath)\u001B[0m\n\u001B[1;32m    468\u001B[0m         data \u001B[38;5;241m=\u001B[39m data\u001B[38;5;241m.\u001B[39mcopy()\n\u001B[1;32m    469\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 470\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[43msanitize_array\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mindex\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mdtype\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcopy\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    472\u001B[0m     manager \u001B[38;5;241m=\u001B[39m get_option(\u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mmode.data_manager\u001B[39m\u001B[38;5;124m\"\u001B[39m)\n\u001B[1;32m    473\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m manager \u001B[38;5;241m==\u001B[39m \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124mblock\u001B[39m\u001B[38;5;124m\"\u001B[39m:\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/programming-languages-w2v-9GOOA69h-py3.10/lib/python3.10/site-packages/pandas/core/construction.py:618\u001B[0m, in \u001B[0;36msanitize_array\u001B[0;34m(data, index, dtype, copy, raise_cast_failure, allow_2d)\u001B[0m\n\u001B[1;32m    616\u001B[0m     data \u001B[38;5;241m=\u001B[39m np\u001B[38;5;241m.\u001B[39marray(data, copy\u001B[38;5;241m=\u001B[39mcopy)\n\u001B[1;32m    617\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 618\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mlist\u001B[39;49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    620\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m dtype \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mlen\u001B[39m(data) \u001B[38;5;241m==\u001B[39m \u001B[38;5;241m0\u001B[39m:\n\u001B[1;32m    621\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m~/.cache/pypoetry/virtualenvs/programming-languages-w2v-9GOOA69h-py3.10/lib/python3.10/site-packages/tqdm/std.py:1195\u001B[0m, in \u001B[0;36mtqdm.__iter__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m   1192\u001B[0m time \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_time\n\u001B[1;32m   1194\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m-> 1195\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m obj \u001B[38;5;129;01min\u001B[39;00m iterable:\n\u001B[1;32m   1196\u001B[0m         \u001B[38;5;28;01myield\u001B[39;00m obj\n\u001B[1;32m   1197\u001B[0m         \u001B[38;5;66;03m# Update and possibly print the progressbar.\u001B[39;00m\n\u001B[1;32m   1198\u001B[0m         \u001B[38;5;66;03m# Note: does not call self.update(1) for speed optimisation.\u001B[39;00m\n",
      "File \u001B[0;32m/usr/lib/python3.10/multiprocessing/pool.py:873\u001B[0m, in \u001B[0;36mIMapIterator.next\u001B[0;34m(self, timeout)\u001B[0m\n\u001B[1;32m    871\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m success:\n\u001B[1;32m    872\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m value\n\u001B[0;32m--> 873\u001B[0m \u001B[38;5;28;01mraise\u001B[39;00m value\n",
      "\u001B[0;31mMaybeEncodingError\u001B[0m: Error sending result: '<multiprocessing.pool.ExceptionWithTraceback object at 0x7fc090124400>'. Reason: 'TypeError(\"cannot pickle '_thread.RLock' object\")'"
     ]
    }
   ],
   "source": [
    "use_cache = True\n",
    "# load \"tokenized_sample.pkl\" from disk if it exists\n",
    "if use_cache and os.path.exists(\"models/tokenized_sample.pkl\"):\n",
    "    tokenized_sample = pd.read_pickle(\"models/tokenized_sample.pkl\")\n",
    "else:\n",
    "    tokenized_sample = tokenize_dataset(dataset, ignore_langs=['C#'])\n",
    "    tokenized_sample.to_pickle(\"models/tokenized_sample.pkl\")\n",
    "\n",
    "tokenized_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lang_model(dataset, complete_model, language):\n",
    "    model = Word2Vec.load(\"models/complete_model.gensim\")\n",
    "    #model = Word2Vec(vector_size=100, window=10, min_count=10, workers=4)\n",
    "    #model.reset_from(complete_model)\n",
    "    model.init_weights()\n",
    "    train_dataset = dataset.code[dataset.language == language]\n",
    "    model.train(train_dataset, total_examples=len(train_dataset), epochs=10)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "complete_model = Word2Vec(vector_size=100, window=10, min_count=10, workers=8)\n",
    "complete_model.build_vocab(tokenized_sample.code)\n",
    "complete_model.save(\"models/complete_model.gensim\")\n",
    "models = [(language, create_lang_model(tokenized_sample, complete_model, language)) for language in tokenized_sample.language.unique()]\n",
    "models"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Visualize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import TranslationMatrix\n",
    "\n",
    "\n",
    "inserted_tokens = [\"INT_LITERAL\", \"FLOAT_LITERAL\", \"STRING_LITERAL\", \"VARIABLE\"]\n",
    "math_ops = [\"+\", \"-\", \"*\", \"/\", \"%\"]\n",
    "common_keywords = [\"if\", \"else\", \"for\", \"while\"]\n",
    "python_keywords = [\"def\", \"class\", \"return\", \"if\", \"else\", \"for\", \"while\", \"in\", \"import\", \"from\", \"as\", \"with\", \"try\", \"except\", \"finally\", \"raise\", \"assert\", \"yield\", \"lambda\", \"pass\", \"break\", \"continue\", \"del\", \"global\", \"nonlocal\", \"and\", \"or\", \"not\", \"is\", \"in\", \"True\", \"False\", \"None\", \"async\", \"await\"]\n",
    "cpp_keywords = [\"class\", \"bool\", \"catch\", \"try\", \"break\", \"continue\", \"delete\", \"do\", \"else\", \"enum\", \"explicit\", \"export\", \"extern\", \"false\", \"for\", \"friend\", \"goto\", \"if\", \"inline\", \"mutable\", \"namespace\", \"new\", \"operator\", \"private\", \"protected\", \"public\", \"register\", \"return\", \"sizeof\", \"static\", \"struct\", \"switch\", \"template\", \"this\", \"throw\", \"true\", \"typedef\", \"typeid\", \"typename\", \"union\", \"using\", \"virtual\", \"volatile\", \"while\"]\n",
    "csharp_keywords = [\"class\", \"bool\", \"catch\", \"try\", \"break\", \"continue\", \"delete\", \"do\", \"else\", \"enum\", \"explicit\", \"export\", \"extern\", \"false\", \"for\", \"friend\", \"goto\", \"if\", \"inline\", \"mutable\", \"namespace\", \"new\", \"operator\", \"private\", \"protected\", \"public\", \"register\", \"return\", \"sizeof\", \"static\", \"struct\", \"switch\", \"template\", \"this\", \"throw\", \"true\", \"typedef\", \"typeid\", \"typename\", \"union\", \"using\", \"virtual\", \"volatile\", \"while\"]\n",
    "go_keywords = [\"break\", \"func\", \"default\", \"type\", \"defer\", \"go\", \"struct\", \"map\", \"chan\", \"else\", \"goto\", \"package\", \"range\", \"const\", \"fallthrough\", \"for\", \"import\", \"interface\", \"return\", \"select\", \"case\", \"continue\", \"if\", \"switch\", \"var\", \"nil\", \"true\", \"false\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO: vectors are different for models so we have to align them, currently we just use least square method\n",
    "#  maybe removing mean vector or something can help.\n",
    "def word_cloud(models: List[Tuple[str, Word2Vec]], words, translation_fix_words):\n",
    "    words = list(set(words))\n",
    "    translation_target = models[0][1].wv[translation_fix_words]\n",
    "    df = pd.DataFrame(columns=[\"model\", \"word\", \"x\", \"y\"])\n",
    "    for name, model in models:\n",
    "        translation_source = model.wv[translation_fix_words]\n",
    "        translation_matrix = np.linalg.lstsq(translation_source, translation_target, rcond=None)[0]\n",
    "        existing_words = [word for word in words if word in model.wv]\n",
    "        vecs = [model.wv[word] @ translation_matrix for word in existing_words]\n",
    "        vecs = np.asarray(vecs)\n",
    "        df = df.append(pd.DataFrame({\"model\": [name] * len(existing_words), \"word\": existing_words, \"x\": vecs[:, 0], \"y\": vecs[:, 1]}))\n",
    "\n",
    "    # visulize 2D with dimensionality reductino\n",
    "    pca = PCA(2, whiten=True)\n",
    "    df[[\"x\", \"y\"]] = pca.fit_transform(df[[\"x\", \"y\"]])\n",
    "    ax = sns.scatterplot(data=df, x=\"x\", y=\"y\", hue=\"model\")\n",
    "    range_x, range_y = np.ptp(df[[\"x\", \"y\"]], axis=0)\n",
    "    for m in df.model.unique():\n",
    "        model_df = df[df.model == m]\n",
    "        for model, word, x, y in model_df.itertuples(index=False):\n",
    "            ax.text(x + 0.005 * range_x, y, word,\n",
    "                verticalalignment='center', horizontalalignment='left', fontsize=8)\n",
    "    return ax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_cloud(models, python_keywords + common_keywords, [w for w in complete_model.wv.key_to_index.keys()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4ba882bed1965a54d4fef669f18faecb8d8e732d30288b3c8a5015454ba0d6c4"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
